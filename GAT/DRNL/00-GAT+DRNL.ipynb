{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ec9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "train_data = torch.load('train_data.pt')\n",
    "val_data = torch.load('val_data.pt')\n",
    "test_data = torch.load('test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e96faf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv1d, MaxPool1d, Linear, Dropout, BCEWithLogitsLoss, GRU\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, aggr, global_sort_pool\n",
    "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80918fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "def seal_processing(dataset, edge_label_index, y):\n",
    "    data_list = []\n",
    "    for src, dst in edge_label_index.t().tolist():\n",
    "        sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph([src, dst], 2, dataset.edge_index, relabel_nodes=True)\n",
    "        src, dst = mapping.tolist()\n",
    "\n",
    "        # Remove target link from the subgraph\n",
    "        mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
    "        mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
    "        sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
    "\n",
    "        # Double-radius node labeling (DRNL)\n",
    "        src, dst = (dst, src) if src > dst else (src, dst)\n",
    "        adj = to_scipy_sparse_matrix(sub_edge_index, num_nodes=sub_nodes.size(0)).tocsr()\n",
    "\n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "        # Calculate the distance between every node and the source target node\n",
    "        d_src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src)\n",
    "        d_src = np.insert(d_src, dst, 0, axis=0)\n",
    "        d_src = torch.from_numpy(d_src)\n",
    "\n",
    "        # Calculate the distance between every node and the destination target node\n",
    "        d_dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1)\n",
    "        d_dst = np.insert(d_dst, src, 0, axis=0)\n",
    "        d_dst = torch.from_numpy(d_dst)\n",
    "\n",
    "        # Calculate the label z for each node\n",
    "        dist = d_src + d_dst\n",
    "        z = 1 + torch.min(d_src, d_dst) + dist // 2 * (dist // 2 + dist % 2 - 1)\n",
    "        z[src], z[dst], z[torch.isnan(z)] = 1., 1., 0.\n",
    "        z = z.to(torch.long)\n",
    "\n",
    "        # Concatenate node features and one-hot encoded node labels (with a fixed number of classes)\n",
    "        node_labels = F.one_hot(z, num_classes=200).to(torch.float)\n",
    "        node_emb = dataset.x[sub_nodes]\n",
    "        node_x = torch.cat([node_emb, node_labels], dim=1)\n",
    "\n",
    "        # Create data object\n",
    "        data = Data(x=node_x, z=z, edge_index=sub_edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cf531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclosing subgraphs extraction\n",
    "train_pos_data_list = seal_processing(train_data, train_data.pos_edge_label_index, 1)\n",
    "train_neg_data_list = seal_processing(train_data, train_data.neg_edge_label_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399be37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pos_data_list = seal_processing(val_data, val_data.pos_edge_label_index, 1)\n",
    "val_neg_data_list = seal_processing(val_data, val_data.neg_edge_label_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90731ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_data_list = seal_processing(test_data, test_data.pos_edge_label_index, 1)\n",
    "test_neg_data_list = seal_processing(test_data, test_data.neg_edge_label_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d337ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_pos_data_list + train_neg_data_list\n",
    "val_dataset = val_pos_data_list + val_neg_data_list\n",
    "test_dataset = test_pos_data_list + test_neg_data_list\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d3b84b-418e-44e9-978d-4d84bb2c0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_in, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        # GCN layers\n",
    "        self.gcn1 = GATConv(dim_in, 32, heads=num_heads, concat=True)\n",
    "        self.gcn2 = GATConv(64,1, heads=1, concat=False)\n",
    "\n",
    "        self.lin1 = Linear(65, dim_in)\n",
    "        self.lin2 = Linear(dim_in, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x1 = self.gcn1(x, edge_index).tanh()\n",
    "        x2 = self.gcn2(x1, edge_index).tanh()\n",
    "        x = torch.cat([x1, x2], dim=-1)\n",
    "\n",
    "        _, center_indices = np.unique(batch.cpu().numpy(), return_index=True)\n",
    "        x_src = x[center_indices]\n",
    "        x_dst = x[center_indices + 1]\n",
    "        x = (x_src * x_dst)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705d5ef0-fa90-4f11-b5a4-fc9597f84ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT(train_dataset[0].num_features,2).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "criterion = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798ab952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out.view(-1), data.y.to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        y_pred.append(out.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "\n",
    "    y_pred_binary = (torch.cat(y_pred) > 0.5).numpy()\n",
    "    y_true_array = torch.cat(y_true).numpy()\n",
    "\n",
    "    auc = roc_auc_score(y_true_array, torch.cat(y_pred))\n",
    "    accuracy = accuracy_score(y_true_array, y_pred_binary)\n",
    "    f1 = f1_score(y_true_array, y_pred_binary)\n",
    "    precision = precision_score(y_true_array, y_pred_binary)\n",
    "    recall = recall_score(y_true_array, y_pred_binary)\n",
    "\n",
    "    return auc, accuracy, f1, precision, recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b665e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | Loss: 0.3151 | Val AUC: 0.7806 \n",
      "Epoch  1 | Loss: 0.2635 | Val AUC: 0.8083 \n",
      "Epoch  2 | Loss: 0.2544 | Val AUC: 0.8204 \n",
      "Epoch  3 | Loss: 0.2474 | Val AUC: 0.8174 \n",
      "Epoch  4 | Loss: 0.2424 | Val AUC: 0.8211 \n",
      "Epoch  5 | Loss: 0.2375 | Val AUC: 0.8230 \n",
      "Epoch  6 | Loss: 0.2326 | Val AUC: 0.8260 \n",
      "Epoch  7 | Loss: 0.2287 | Val AUC: 0.8162 \n",
      "Epoch  8 | Loss: 0.2252 | Val AUC: 0.8275 \n",
      "Epoch  9 | Loss: 0.2210 | Val AUC: 0.8173 \n",
      "Epoch 10 | Loss: 0.2178 | Val AUC: 0.8325 \n",
      "Epoch 11 | Loss: 0.2154 | Val AUC: 0.8312 \n",
      "Epoch 12 | Loss: 0.2123 | Val AUC: 0.8249 \n",
      "Epoch 13 | Loss: 0.2102 | Val AUC: 0.8303 \n",
      "Epoch 14 | Loss: 0.2077 | Val AUC: 0.8204 \n",
      "Epoch 15 | Loss: 0.2055 | Val AUC: 0.8256 \n",
      "Epoch 16 | Loss: 0.2027 | Val AUC: 0.8296 \n",
      "Epoch 17 | Loss: 0.2018 | Val AUC: 0.8361 \n",
      "Epoch 18 | Loss: 0.1986 | Val AUC: 0.8314 \n",
      "Epoch 19 | Loss: 0.1977 | Val AUC: 0.8320 \n",
      "Epoch 20 | Loss: 0.1946 | Val AUC: 0.8280 \n",
      "Epoch 21 | Loss: 0.1941 | Val AUC: 0.8248 \n",
      "Epoch 22 | Loss: 0.1921 | Val AUC: 0.8301 \n",
      "Epoch 23 | Loss: 0.1898 | Val AUC: 0.8290 \n",
      "Epoch 24 | Loss: 0.1887 | Val AUC: 0.8295 \n",
      "Epoch 25 | Loss: 0.1865 | Val AUC: 0.8292 \n",
      "Epoch 26 | Loss: 0.1847 | Val AUC: 0.8300 \n",
      "Epoch 27 | Loss: 0.1833 | Val AUC: 0.8276 \n",
      "Epoch 28 | Loss: 0.1824 | Val AUC: 0.8294 \n",
      "Epoch 29 | Loss: 0.1808 | Val AUC: 0.8317 \n",
      "Epoch 30 | Loss: 0.1784 | Val AUC: 0.8316 \n",
      "Epoch 31 | Loss: 0.1769 | Val AUC: 0.8279 \n",
      "Epoch 32 | Loss: 0.1758 | Val AUC: 0.8296 \n",
      "Epoch 33 | Loss: 0.1743 | Val AUC: 0.8267 \n",
      "Epoch 34 | Loss: 0.1725 | Val AUC: 0.8278 \n",
      "Epoch 35 | Loss: 0.1725 | Val AUC: 0.8291 \n",
      "Epoch 36 | Loss: 0.1700 | Val AUC: 0.8274 \n",
      "Epoch 37 | Loss: 0.1687 | Val AUC: 0.8254 \n",
      "Epoch 38 | Loss: 0.1677 | Val AUC: 0.8271 \n",
      "Epoch 39 | Loss: 0.1664 | Val AUC: 0.8296 \n",
      "Epoch 40 | Loss: 0.1652 | Val AUC: 0.8260 \n",
      "Epoch 41 | Loss: 0.1651 | Val AUC: 0.8264 \n",
      "Epoch 42 | Loss: 0.1629 | Val AUC: 0.8260 \n",
      "Epoch 43 | Loss: 0.1613 | Val AUC: 0.8290 \n",
      "Epoch 44 | Loss: 0.1602 | Val AUC: 0.8271 \n",
      "Epoch 45 | Loss: 0.1596 | Val AUC: 0.8274 \n",
      "Epoch 46 | Loss: 0.1585 | Val AUC: 0.8284 \n",
      "Epoch 47 | Loss: 0.1579 | Val AUC: 0.8262 \n",
      "Epoch 48 | Loss: 0.1570 | Val AUC: 0.8252 \n",
      "Epoch 49 | Loss: 0.1552 | Val AUC: 0.8268 \n",
      "Epoch 50 | Loss: 0.1545 | Val AUC: 0.8268 \n",
      "Epoch 51 | Loss: 0.1537 | Val AUC: 0.8273 \n",
      "Epoch 52 | Loss: 0.1535 | Val AUC: 0.8290 \n",
      "Epoch 53 | Loss: 0.1523 | Val AUC: 0.8258 \n",
      "Epoch 54 | Loss: 0.1516 | Val AUC: 0.8254 \n",
      "Epoch 55 | Loss: 0.1503 | Val AUC: 0.8265 \n",
      "Epoch 56 | Loss: 0.1499 | Val AUC: 0.8234 \n",
      "Epoch 57 | Loss: 0.1492 | Val AUC: 0.8282 \n",
      "Epoch 58 | Loss: 0.1482 | Val AUC: 0.8268 \n",
      "Epoch 59 | Loss: 0.1479 | Val AUC: 0.8254 \n",
      "Epoch 60 | Loss: 0.1473 | Val AUC: 0.8270 \n",
      "Epoch 61 | Loss: 0.1462 | Val AUC: 0.8276 \n",
      "Epoch 62 | Loss: 0.1461 | Val AUC: 0.8245 \n",
      "Epoch 63 | Loss: 0.1451 | Val AUC: 0.8256 \n",
      "Epoch 64 | Loss: 0.1450 | Val AUC: 0.8248 \n",
      "Epoch 65 | Loss: 0.1445 | Val AUC: 0.8243 \n",
      "Epoch 66 | Loss: 0.1433 | Val AUC: 0.8249 \n",
      "Epoch 67 | Loss: 0.1425 | Val AUC: 0.8260 \n",
      "Epoch 68 | Loss: 0.1429 | Val AUC: 0.8224 \n",
      "Epoch 69 | Loss: 0.1419 | Val AUC: 0.8253 \n",
      "Epoch 70 | Loss: 0.1407 | Val AUC: 0.8243 \n",
      "Epoch 71 | Loss: 0.1417 | Val AUC: 0.8245 \n",
      "Epoch 72 | Loss: 0.1408 | Val AUC: 0.8196 \n",
      "Epoch 73 | Loss: 0.1404 | Val AUC: 0.8252 \n",
      "Epoch 74 | Loss: 0.1392 | Val AUC: 0.8234 \n",
      "Epoch 75 | Loss: 0.1391 | Val AUC: 0.8226 \n",
      "Epoch 76 | Loss: 0.1386 | Val AUC: 0.8223 \n",
      "Epoch 77 | Loss: 0.1380 | Val AUC: 0.8213 \n",
      "Epoch 78 | Loss: 0.1380 | Val AUC: 0.8248 \n",
      "Epoch 79 | Loss: 0.1374 | Val AUC: 0.8221 \n",
      "Epoch 80 | Loss: 0.1368 | Val AUC: 0.8231 \n",
      "Epoch 81 | Loss: 0.1364 | Val AUC: 0.8241 \n",
      "Epoch 82 | Loss: 0.1372 | Val AUC: 0.8221 \n",
      "Epoch 83 | Loss: 0.1360 | Val AUC: 0.8236 \n",
      "Epoch 84 | Loss: 0.1347 | Val AUC: 0.8217 \n",
      "Epoch 85 | Loss: 0.1350 | Val AUC: 0.8213 \n",
      "Epoch 86 | Loss: 0.1343 | Val AUC: 0.8176 \n",
      "Epoch 87 | Loss: 0.1353 | Val AUC: 0.8208 \n",
      "Epoch 88 | Loss: 0.1348 | Val AUC: 0.8213 \n",
      "Epoch 89 | Loss: 0.1345 | Val AUC: 0.8182 \n",
      "Epoch 90 | Loss: 0.1334 | Val AUC: 0.8219 \n",
      "Epoch 91 | Loss: 0.1333 | Val AUC: 0.8233 \n",
      "Epoch 92 | Loss: 0.1332 | Val AUC: 0.8189 \n",
      "Epoch 93 | Loss: 0.1323 | Val AUC: 0.8211 \n",
      "Epoch 94 | Loss: 0.1334 | Val AUC: 0.8205 \n",
      "Epoch 95 | Loss: 0.1321 | Val AUC: 0.8212 \n",
      "Epoch 96 | Loss: 0.1320 | Val AUC: 0.8195 \n",
      "Epoch 97 | Loss: 0.1316 | Val AUC: 0.8217 \n",
      "Epoch 98 | Loss: 0.1322 | Val AUC: 0.8210 \n",
      "Epoch 99 | Loss: 0.1313 | Val AUC: 0.8224 \n",
      "Test AUC: 0.7595 | Test Accuracy: 0.7112 | Test F1: 0.6927 | Test Precision: 0.7402 | Test Recall: 0.6509\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss = []\n",
    "for epoch in range(100):\n",
    "    loss = train()\n",
    "    val_results = test(val_loader)\n",
    "    val_auc, val_accuracy, val_f1, val_precision, val_recall = val_results\n",
    "    print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} ')\n",
    "    train_loss.append(loss)\n",
    "\n",
    "test_results = test(test_loader)\n",
    "test_auc, test_accuracy, test_f1, test_precision, test_recall = test_results \n",
    "print(f'Test AUC: {test_auc:.4f} | Test Accuracy: {test_accuracy:.4f} | Test F1: {test_f1:.4f} | Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9171997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece6569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
